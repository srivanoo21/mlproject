[ 2023-03-28 23:13:39,039 ] 23 root - INFO - Entered the data ingestion method or component
[ 2023-03-28 23:13:39,043 ] 26 root - INFO - Read the dataset as dataframe
[ 2023-03-28 23:13:39,049 ] 32 root - INFO - Train Test split initiated
[ 2023-03-28 23:13:39,060 ] 38 root - INFO - Ingestion of the data is completed
[ 2023-03-28 23:13:39,079 ] 73 root - INFO - Train and test data read completed
[ 2023-03-28 23:13:39,079 ] 74 root - INFO - Obtaining preprocessing object
[ 2023-03-28 23:13:39,079 ] 55 root - INFO - Numerical columns encoding is completed
[ 2023-03-28 23:13:39,079 ] 56 root - INFO - Numerical columns: ['reading_score', 'writing_score']
[ 2023-03-28 23:13:39,079 ] 58 root - INFO - Categorical columns encoding is completed
[ 2023-03-28 23:13:39,079 ] 59 root - INFO - Categorical columns: ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']
[ 2023-03-28 23:13:39,079 ] 87 root - INFO - Appying preprocessing object on training and testing dataframe
[ 2023-03-28 23:13:39,103 ] 95 root - INFO - Saved preprocessing object..
[ 2023-03-28 23:13:39,109 ] 32 root - INFO - Split training and testing data
[ 2023-03-28 23:13:39,109 ] 36 root - INFO - Training and testing data has been split
[ 2023-03-28 23:14:40,707 ] 37 root - INFO - Best parameters for RandomForestRegressor() is {'max_depth': 8, 'min_samples_leaf': 4, 'n_estimators': 60}
[ 2023-03-28 23:14:41,344 ] 37 root - INFO - Best parameters for DecisionTreeRegressor() is {'criterion': 'squared_error', 'min_samples_leaf': 3}
[ 2023-03-28 23:14:49,004 ] 37 root - INFO - Best parameters for GradientBoostingRegressor() is {'loss': 'squared_error', 'n_estimators': 50}
[ 2023-03-28 23:14:49,400 ] 37 root - INFO - Best parameters for LinearRegression() is {}
[ 2023-03-28 23:14:50,170 ] 37 root - INFO - Best parameters for KNeighborsRegressor() is {'n_neighbors': 10}
[ 2023-03-28 23:15:29,232 ] 37 root - INFO - Best parameters for XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=None, num_parallel_tree=None,
             predictor=None, random_state=None, ...) is {'eta': 0.1, 'max_depth': 4, 'n_estimators': 50}
[ 2023-03-28 23:15:42,428 ] 37 root - INFO - Best parameters for <catboost.core.CatBoostRegressor object at 0x000001897CAF5EE0> is {}
[ 2023-03-28 23:16:07,213 ] 37 root - INFO - Best parameters for AdaBoostRegressor() is {'learning_rate': 0.1, 'n_estimators': 120}
[ 2023-03-28 23:16:07,472 ] 95 root - INFO - Model report {'Random Forest': 0.8533092133126958, 'Decision Tree': 0.7945007971523516, 'Gradient Boosting': 0.8688042017615204, 'Linear Regression': 0.8803737785720934, 'K-Neighbors Regressor': 0.5077612082597731, 'XgbRegressor': 0.8674931846320061, 'CatBoosting Regressor': 0.8518305378322716, 'AdaBoost Regressor': 0.8370063779393722}
[ 2023-03-28 23:16:07,472 ] 99 root - INFO - Best model score is 0.8803737785720934
[ 2023-03-28 23:16:07,472 ] 103 root - INFO - Best model name is Linear Regression
[ 2023-03-28 23:16:07,472 ] 110 root - INFO - Best model found on both training and testing dataset
[ 2023-03-28 23:16:07,475 ] 119 root - INFO - Test data has been predicted
